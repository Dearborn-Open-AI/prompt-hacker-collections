# GPT 最佳实践

本指南分享了从 GPT（生成式预训练模型）中获得更好结果的策略和战术。这里描述的方法有时可以结合使用以获得更大的效果。我们鼓励尝试不同的方法，找到最适合自己的方法。

一些在这里展示的示例目前仅适用于我们最强大的模型 gpt-4。如果您尚未获得 gpt-4 的访问权限，请考虑加入等待列表。一般而言，如果您发现一个 GPT 模型在某个任务上失败了，并且有一个更强大的模型可用，通常值得尝试使用更强大的模型再次尝试。

## 获取更好结果的六个策略

### 1. 写明确的指令

GPT 无法阅读您的思维。如果它们的输出过长，请要求简短回复。如果它们的输出过于简单，请要求专家级的写作。如果您不喜欢格式，请展示您想要看到的格式。GPT 越不需要猜测您的意图，您获得满意结果的可能性就越大。

#### 战术：

- 在查询中包含详细信息以获得更相关的答案
- 要求模型采用特定角色形象
- 使用分隔符清楚地指示输入的不同部分
- 指定完成任务所需的步骤
- 提供示例
- 指定输出的期望长度
- 提供参考文本

GPT 可以自信地编写虚假答案，尤其是在问及生僻话题、引用文献和网址时。就像学生在考试时用一张笔记纸可以帮助他们取得更好的成绩一样，向 GPT 提供参考文本可以帮助它用更少的虚构来回答问题。

#### 战术：

- 指示模型使用参考文本回答问题
- 指示模型使用参考文本的引用进行回答
- 将复杂任务分解为更简单的子任务
- 就像在软件工程中将复杂系统分解为一组模块化组件一样，在提交给 GPT 的任务中也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为一系列较简单任务的工作流程，其中较早任务的输出被用于构造后续任务的输入。

#### 战术：

- 使用意图分类来识别用户查询的最相关指令
- 对于需要非常长对话的对话应用程序，可以对先前对话进行

摘要或过滤
- 将长文档分段进行摘要，并以递归方式构建完整摘要
- 给 GPT 充分的时间“思考”

如果要求它计算 17 乘以 28，您可能不会立即知道答案，但可以在一段时间内计算出来。同样，GPT 在试图立即回答问题时会出现更多推理错误，而不是花时间计算出答案。在回答之前要求进行一系列推理可以帮助 GPT 更可靠地推理出正确答案。

#### 战术：

- 指示模型在得出结论之前自己思考解决方案
- 使用内心独白或一系列查询来隐藏模型的推理过程
- 询问模型在先前的处理中是否遗漏了任何内容
- 使用外部工具

通过将其他工具的输出输入到 GPT 中，可以弥补 GPT 的弱点。例如，一个文本检索系统可以告诉 GPT 相关文档的信息。一个代码执行引擎可以帮助 GPT 进行数学计算和代码运行。如果一个任务可以通过工具而不是 GPT 更可靠或高效地完成，那么将其卸载给工具可以获得最佳结果。

#### 战术：

- 使用基于嵌入的搜索来实现高效的知识检索
- 使用代码执行来进行更准确的计算或调用外部 API

## 系统地进行测试更改

如果您能够对性能进行量化测量，那么改进性能就会更容易。在某些情况下，对提示进行修改可能会在一些孤立的示例上取得更好的性能，但在更具代表性的示例集上导致性能下降。因此，为了确保更改对性能的净正效果，可能需要定义一个全面的测试套件（也称为“评估”）。

#### 战术：

- 使用参考标准答案评估模型输出

## 战术

上述每个策略都可以通过具体的战术进行实施。这些战术旨在提供尝试的思路。它们并不是完全详尽的，您可以随意尝试不在此处列出的创造性想法。

### 策略：写明确的指令

#### 战术：在查询中包含详细信息以获得更相关的答案

为了获得高度相关的回复，请确保请求提供任何重要的细节或上下文。否则，您让模型猜测您的意思。

下面是一些示例，展示了更好的写法：

坏的写法 | 好的写法
---

 | ---
如何在 Excel 中添加数字？ | 如何在 Excel 中将一行美元金额相加？我想要自动对整个工作表的行进行这个操作，所有的总和都会在右边的名为“总计”的列中。
谁是总统？ | 谁是 2021 年墨西哥的总统？选举频率是多少？
编写计算斐波那契数列的代码。 | 用 TypeScript 编写一个高效计算斐波那契数列的函数。请在代码中详细注释说明每个部分的作用和为什么以这种方式编写。
总结会议记录。 | 用一个段落总结会议记录。然后按照演讲者的名单和他们的关键观点写一个 markdown 列表。最后，列出演讲者建议的下一步或行动项（如果有）。

#### 战术：要求模型采用特定角色形象

可以使用系统消息来指定模型在回复中使用的角色形象。

系统：
当我寻求撰写帮助时，您将在每个段落中包含至少一个笑话或趣味评论。

用户：
给我的螺栓供应商写一封感谢信，感谢他们及时交货并在短时间内完成。这使我们能够交付重要订单。

#### 战术：使用分隔符清楚地指示输入的不同部分

像三重引号、XML 标记、章节标题等分隔符可以帮助标明文本的不同部分，以便进行不同的处理。

用户：
用三重引号将文本进行分隔，并用俳句总结。

```
在这里插入文本
```

系统：
您将获得一对关于同一主题的文章（用 XML 标记分隔）。首先总结每篇文章的论点，然后指出哪篇文章有更好的论证，并解释原因。

用户：
<article>在这里插入第一篇文章</article>

<article>在这里插入第二篇文章</article>

系统：
您将获得一篇论文摘要和一个建议的标题。论文标题应该让读者对论文的主题有一个很好的理解，但同时也要引人注目。如果标题不符合这些标准，请提供5个备选标题。

用户：
摘要：在这里插入摘要

标题：在这里插入标题

对于诸如此类的简单任务，使用分隔符可能不会对输出质量产生影响。然而，任务越复杂，区分任务细节的重要性就越大。不要让 GPT 花力气理解您要求它做什么。

#### 战术：指定完成任务所需的步骤



某些任务最好被指定为一系列步骤。明确写出这些步骤可以使模型更容易遵循。

系统：
使用以下逐步说明来回应用户输入。

步骤1 - 用户将用三重引号提供文本。用带有前缀“Summary: ”的一句话总结这段文本。

步骤2 - 将第1步中的摘要翻译成西班牙语，前缀为“Translation: ”。

用户：
```在这里插入文本```

#### 战术：提供示例

通常，提供适用于所有示例的一般说明比通过示例演示任务的所有排列组合更高效，但在某些情况下，提供示例可能更容易。例如，如果您希望模型复制一种难以明确描述的用户查询响应方式时。这被称为“few-shot”提示。

系统：
以一种一致的风格回答。

用户：
教我耐心。

助理：
雕刻最深谷的河流起源于一眼泉水；最壮丽的交响乐从单个音符开始；最复杂的挂毯由一根孤独的线开始。

用户：
教我关于海洋的事情。

#### 战术：指定输出的期望长度

您可以要求模型生成指定目标长度的输出。目标输出长度可以按照单词数、句子数、段落数、项目符号数等进行指定。但请注意，指示模型生成特定数量的单词并不具有高精度。模型更可靠地生成具有特定数量段落或项目符号的输出。

用户：
用大约50个单词总结用三重引号分隔的文本。

```在这里插入文本```

用户：
用2段话总结用三重引号分隔的文本。

```在这里插入文本```

用户：
用3个项目符号总结用三重引号分隔的文本。

```在这里插入文本```

## 策略：提供参考文本

#### 战术：指示模型使用参考文本回答问题

如果我们可以为模型提供与当前查询相关的可信信息，那么我们可以指示模型使用提供的信息来构成答案。

系统：
使用用三重引号分隔的提供的文章来回答问题。如果无法在文章中找到答案，请写下“我找不到答案”。

用户：
<插入由三重引号分隔的文章>

问题：<插入问题>

鉴于 GPT 的上下文窗口有限，为了应用这种策略，我们需要一种动态查找与所提问的问题相关的信息的方法。嵌入可以用来实现高效的知

识检索。请参阅战术“使用基于嵌入的搜索来实现高效的知识检索”以了解如何实施。

#### 战术：指示模型使用参考文本回答并引用文献

如果输入已补充有相关知识，可以直接要求模型通过引用提供的文档中的段落来为其答案添加引用。请注意，输出中的引用可以通过在提供的文档中进行字符串匹配来进行程序验证。

系统：
您将获得由三重引号分隔的文档和一个问题。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档的段落。如果文档不包含回答问题所需的信息，则只需写下“信息不足”。如果提供了问题的答案，则必须带有引文注释。请使用以下格式引用相关段落（{"citation": ...}）。

用户：
```<在此插入文档>```

<在此插入问题>

#### 策略：将复杂任务拆分为更简单的子任务

#### 战术：使用意图分类以识别用户查询中最相关的指令

对于需要处理不同情况下的大量独立指令集的任务，首先对查询进行分类并根据分类确定所需的指令可能是有益的。这可以通过定义固定的类别并硬编码与处理给定类别任务相关的指令来实现。此过程也可以递归应用于将任务分解为一系列阶段。这种方法的优势在于，每个查询仅包含执行任务下一阶段所需的指令，这可能会导致与使用单个查询执行整个任务相比较低的错误率。这还可能会降低成本，因为更大的提示费用更高（请参阅定价信息）。

例如，假设对于客户服务应用程序，查询可以如下进行有意义的分类：

系统：
您将获得客户服务查询。将每个查询分类为主要类别和次要类别。以 json 格式提供输出，使用以下键：primary 和 secondary。

主要类别：计费、技术支持、账户管理或一般咨询。

计费的次要类别：
- 退订或升级
- 添加付款方式
- 对费用进行解释
- 争议费用

技术支持的次要类别：
- 故障排除
- 设备兼容性
- 软件更新

账户管理的次要类别：
- 密码重置
- 更新个人信息
- 关闭账户
- 账户安全

一般咨询的次要类别：
- 产品信息
- 定价
- 反馈
- 联系人工客服

用户：
我需要让我的互联网重新工作起来。

基于客户查询的分类，可以提供一组更具体的指令给 GPT

 模型来处理后续步骤。例如，假设客户需要帮助进行“故障排除”。

系统：
您将获得需要在技术支持环境中进行故障排除的客户服务查询。帮助用户：

- 要求他们检查路由器的所有连接的电缆。请注意，电缆随着时间的推移可能会松动。
- 如果所有电缆连接正常但问题仍然存在，请询问他们使用的路由器型号
- 现在，您将指导他们如何重新启动设备：
-- 如果型号为 MTD-327J，请指导他们按下红色按钮并保持按压 5 秒钟，然后在测试连接之前等待 5 分钟。
-- 如果型号为 MTD-327S，请指导他们拔下插头，然后重新插入，然后在测试连接之前等待 5 分钟。
- 如果客户在重新启动设备并等待 5 分钟后仍然遇到问题，请输出 {"IT support requested"} 将他们连接到 IT 支持。
- 如果用户开始询问与此主题无关的问题，请确认他们是否希望结束当前有关故障排除的聊天，并根据以下方案对其请求进行分类：

<在此插入上述主/次要分类方案>

用户：
我需要让我的互联网重新工作起来。

请注意，已指示模型发出特殊字符串来指示对话状态的变化。这使我们能够将系统转换为一个状态机，其中状态确定了应插入哪些指令。通过跟踪状态、在该状态下相关的指令以及可选地从该状态允许进行的状态转换，我们可以在用户体验周围设置限制，这在使用较少结构化的方法时很难实现。

#### 战术：对于需要非常长对话的对话应用程序，逐段总结或过滤之前的对话

由于 GPT 模型具有固定的上下文长度，在用户和助手之间的对话中，包括整个对话在上下文窗口中的情况是不可持续的。

对于这个问题有各种解决办法之一是逐段总结前面的对话。一旦输入的大小达到预定的阈值长度，这将触发一个查询，对对话的一部分进行总结，并且前一对话的总结可以作为系统消息的一部分包含在内。另外，还可以在整个对话期间异步地对先前的对话进行总结。

另一种替代解决方案是动态选择与当前查询最相关的先前对话部分。请参阅战术“使用基于嵌入的搜索来实现高效的知识检索”，了解如何实施

此策略。

#### 战术：逐段对长文档进行总结，并递归构建完整摘要

由于 GPT 模型具有固定的上下文长度，无法在单个查询中总结超过上下文长度减去生成摘要长度的文本。

要总结非常长的文档（例如书籍），可以使用一系列查询来总结文档的每个部分。可以连接并总结部分摘要，从而生成摘要的摘要。此过程可以递归进行，直到完全总结整个文档。如果需要使用早期部分的信息来理解后面的部分，则可以使用一种更进一步的技巧，即在总结该点的内容时，包含之前文本的运行摘要。这种过程用于总结书籍的有效性已经在 OpenAI 的先前研究中使用 GPT-3 的变体进行了研究。

#### 策略：给予 GPTs 足够的时间来“思考”

#### 战术：在着手得出结论之前，指示模型自行解决问题

有时候，我们在明确指示模型在得出结论之前从第一原则进行推理时会获得更好的结果。例如，假设我们希望模型评估学生对数学问题的解决方案。最明显的方法是简单地询问模型学生的解决方案是否正确。

系统：
确定学生的解决方案是否正确。
用户：
问题陈述：我正在建造一个太阳能发电装置，需要帮助计算财务状况。
- 土地成本为每平方英尺 100 美元
- 我可以以每平方英尺 250 美元的价格购买太阳能电池板
- 我谈判了一个维护合同，每年的费用是固定的 10 万美元，另外每平方英尺还要额外支付 10 美元
作为平方英尺数量的函数，第一年运营的总成本是多少？

学生的解决方案：设 x 为平方英尺的安装面积。
1. 土地成本：100x
2. 太阳能电池板成本：250x
3. 维护成本：10 万美元 + 100x
总成本：100x + 250x + 10 万美元 + 100x = 450x + 10 万美元
助手：
学生的解决方案是正确的。

但学生的解决方案实际上是错误的！我们可以通过提示模型首先生成自己的解决方案来使模型成功注意到这一点。

系统：
首先自行解决问题。然后将您的解决方

案与学生的解决方案进行比较，并评估学生的解决方案是否正确。在完成问题之前，请不要决定学生的解决方案是否正确。
用户：
问题陈述：我正在建造一个太阳能发电装置，需要帮助计算财务状况。
- 土地成本为每平方英尺 100 美元
- 我可以以每平方英尺 250 美元的价格购买太阳能电池板
- 我谈判了一个维护合同，每年的费用是固定的 10 万美元，另外每平方英尺还要额外支付 10 美元
作为平方英尺数量的函数，第一年运营的总成本是多少？

学生的解决方案：设 x 为平方英尺的安装面积。
1. 土地成本：100x
2. 太阳能电池板成本：250x
3. 维护成本：10 万美元 + 100x
总成本：100x + 250x + 10 万美元 + 100x = 450x + 10 万美元
助手：
设 x 为平方英尺的安装面积。
1. 土地成本：100x
2. 太阳能电池板成本：250x
3. 维护成本：10 万美元 + 10x
总成本：100x + 250x + 10 万美元 + 10x = 360x + 10 万美元

学生的解决方案是不正确的。他们在维护成本计算中犯了一个错误，使用了 100x 而不是 10x。第一年运营的正确总成本为 360x + 10 万美元。

#### 战术：使用内心独白或一系列查询隐藏模型的推理过程

前面的战术说明了在回答特定问题之前，模型有时需要详细推理问题。对于某些应用程序，模型对学生的解决方案的推理过程可能不适合与用户共享。例如，在辅导应用程序中，我们可能希望鼓励学生自己解答问题，但模型对学生解决方案的推理过程可能会向学生透露答案。

内心独白是一种可以缓解这个问题的战术。内心独白的想法是指示模型将希望对用户隐藏的输出部分放入易于解析的结构化格式中。然后，在将输出呈现给用户之前，解析输出并只显示部分输出。

系统：
按照以下步骤回答用户的查询。

第 1 步 - 首先自行解决问题。不要依

赖学生的解决方案，因为它可能是不正确的。将此步骤中的所有内容放在三重引号（""""""）之间。

第 2 步 - 将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。将此步骤中的所有内容放在三重引号（""""""）之间。

第 3 步 - 如果学生犯了错误，请确定您可以给出的提示，而不会透露答案。将此步骤中的所有内容放在三重引号（""""""）之间。

第 4 步 - 如果学生犯了错误，请向学生提供前面步骤中的提示（在三重引号之外）。不要写“第 4 步 - ...”，而是写“提示：”。

用户：
问题陈述："""<插入问题陈述>"""

学生的解决方案："""<插入学生的解决方案>"""
 
另一种方法是使用一系列查询，其中除最后一个之外的所有查询的输出对最终用户隐藏起来。

首先，我们可以要求模型自行解决问题。由于这个初始查询不需要学生的解决方案，因此可以省略。这样做的额外好处是模型的解决方案不会受到学生尝试的解决方案的影响。

用户：
<插入问题陈述>
 
接下来，我们可以让模型使用所有可用的信息来评估学生的解决方案的正确性。

系统：
将您的解决方案与学生的解决方案进行比较，并评估学生的解决方案是否正确。
 
用户：
问题陈述："""<插入问题陈述>"""

您的解决方案："""<插入模型生成的解决方案>"""

学生的解决方案："""<插入学生的解决方案>"""
 
最后，我们可以让模型利用自己的分析，以有益的辅导员角色构建回复。

系统：
您是一位数学辅导员。如果学生犯了错误，请以不透露答案的方式给学生提供提示。如果学生没有犯错误，请给他们一个鼓励的评论。
 
用户：
问题陈述："""<插入问题陈述>"""

您的解决方案："""<插入模型生成的解决方案>"""

学生的解决方案："""<插入学生的解决方案>"""

分析："""<插入前一步骤的模型生成的分析>"""

#### 战术：询问模型在之前的处理中是否遗漏了任何内容

假设我们使用模型列出与特定问题相关的来源摘录。在列出每

个摘录后，模型需要确定是否应开始编写另一个摘录，还是应停止。如果源文档很大，模型通常会过早停止并未列出所有相关的摘录。在这种情况下，通过使用后续查询提示模型查找之前遗漏的摘录，通常可以获得更好的性能。

系统：
您将获得由三重引号限定的文档。您的任务是选择与以下问题相关的摘录：“人工智能的历史上发生了哪些重大范式转变”。

确保摘录包含解释它们所需的所有相关上下文-换句话说，不要提取缺少重要上下文的小片段。以以下 JSON 格式提供输出：

[{"摘录": "..."},
...
{"摘录": "..."}]
用户：
"""<插入文档>"""
助手：
[{"摘录": "模型在这里写入一个摘录"},
...
{"摘录": "模型在这里写入另一个摘录"}]
用户：
是否还有更多相关摘录？请注意不要重复摘录。同时确保摘录包含解释它们所需的所有相关上下文。
 
策略：使用外部工具

#### 战术：使用基于嵌入的搜索来实现高效的知识检索

如果提供作为其输入的信息的一部分，模型可以利用外部信息源。这可以帮助模型生成更准确和更及时的回答。例如，如果用户提出关于特定电影的问题，将有关该电影的高质量信息（例如演员、导演等）添加到模型的输入可能很有用。嵌入可以用于实现高效的知识检索，以便在运行时动态地将相关信息添加到模型输入中。

文本嵌入是一种可以衡量文本字符串之间关系的向量。相似或相关的字符串将比不相关的字符串更接近。这一事实以及快速的向量搜索算法的存在意味着可以使用嵌入来实现高效的知识检索。具体而言，文本语料库可以分成多个部分，并且每个部分都可以进行嵌入和存储。然后，可以对给定的查询进行嵌入，并进行向量搜索，以找到与查询最相关的语料库中的嵌入文本部分（即在嵌入空间中最接近的部分）。

OpenAI Cookbook 中可以找到示例实现。有关如何使用知识检索来最小化模型编造错误事实的示例，请参阅战术“指示模型使用检索到的知识来回答查询”。

#### 战术：使用代码执行进行更准确的计算或调用外部 API

GPT

 模型本身不能保证在进行算术或长时间计算时能够准确执行。在需要时，可以指示模型编写和运行代码来执行计算，而不是进行自己的计算。特别是，可以指示模型将要运行的代码放入指定格式（例如三重反引号）中。在生成输出后，可以提取和运行代码。最后，如果需要，代码执行引擎（即 Python 解释器）的输出可以作为下一个查询的模型输入。

系统：
您可以通过将代码放入三重反引号中来编写和执行 Python 代码，例如```这里放置代码```。使用它来执行计算。

用户：
查找以下多项式的所有实数根：3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10。
 
代码执行的另一个很好的用例是调用外部 API。如果模型按照正确使用 API 的方式进行指导，它可以编写使用该 API 的代码。可以通过向模型提供文档和/或代码示例来指示它如何使用 API。

系统：
您可以通过将代码放入三重反引号中来编写和执行 Python 代码。此外，请注意您可以使用以下模块帮助用户向朋友发送消息：

```python
import message
message.write(to="John", message="嘿，下班后想见面吗？")```
 
警告：执行模型生成的代码并不绝对安全，在使用此功能的应用程序中应采取预防措施。特别是，需要一个沙盒式的代码执行环境来限制不受信任的代码可能造成的伤害。

策略：系统化地测试更改

有时候很难判断一个更改（例如，新的指令或新的设计）是让系统变得更好还是更差。查看几个例子可能会暗示哪个更好，但是样本量小的情况下很难区分真正的改进和随机运气。也许这个更改在一些输入上有助于性能，但在其他输入上却有损性能。

评估过程（或“evals”）对于优化系统设计非常有用。好的评估应该具备以下特点：

- 代表实际使用情况（或至少具有多样性）
- 包含大量的测试用例，以获得更高的统计能力（请参见下表中的指南）
- 易于自动化或重复进行

DIFFERENCE TO DETECT | SAMPLE SIZE NEEDED FOR 95% CONFIDENCE
- 30% | 约10个
- 10% | 约100个
- 3% | 约1,000个
- 1% | 约10,000个

输出的评估可以由计算机、人类或二者混合来进行。计算机可以通过客观标准（例如，带有单个正确答案的问题）自动化评估，也可以通过其他模型查询评估模型输出的一些主观或模糊标准。OpenAI Evals 是一个开源的软件框架，提供了创建自动化评估的工具。

当存在一系列可能被认为具有相等高质量的输出（例如，对于有长答案的问题）时，基于模型的评估可以非常有用。基于模型的评估与需要人工评估的界限模糊不清，并且随着模型的能力增强，这个界限不断变化。我们鼓励尝试来确定基于模型的评估在您的用例中能够工作得有多好。

战术：通过参考黄金标准答案评估模型输出

假设我们知道问题的正确答案应参考一组特定的已知事实。然后，我们可以使用模型查询来计算答案中包含了多少个所需事实。

例如，使用以下系统消息：

系统：
您将获得由三重引号限定的文本，这应该是对问题的答案。检查答案中是否直接包含了以下信息：

- 尼尔·阿姆斯特朗（Neil Armstrong）是第一个登上月球的人。
- 尼尔·阿姆斯特朗（Neil Armstrong）第一次登上月球的日期是1969年7月21日。

对于每个点，执行以下步骤：

1 - 重新陈述该点。
2 - 提供与该点

最接近的答案中的引用。
3 - 考虑读取引用的人是否可以直接推断出该点。在下定论之前，请解释为什么或为什么不。
4 - 如果答案是肯定的，则写入“yes”；否则写入“no”。

最后，提供一个“yes”答案的计数。将该计数提供为{"count": <insert count here>}。

以下是满足这两个要点的示例输入：

系统：
<insert system message above>

用户：
"""尼尔·阿姆斯特朗因成为第一个踏上月球的人而闻名。这一历史性事件发生在1969年7月21日，当时进行了阿波罗11号任务。"""

以下是仅满足一个要点的示例输入：

系统：
<insert system message above>

用户：
"""尼尔·阿姆斯特朗（Neil Armstrong）在迈出登月舱的那一刻创造了历史，成为第一个在月球上行走的人。"""

以下是一个没有满足任何要点的示例输入：

系统：
<insert system message above>

用户：
"""在'69年夏天，一次伟大的航程，
阿波罗11号，英勇如传说之手。
阿姆斯特朗（Armstrong）迈出了一步，历史展开，
他说：“这是人类的一小步，也是人类的一大步，为了一个新世界。”"""

这种基于模型的评估可以有很多可能的变体。考虑以下变体，该变体跟踪候选答案和黄金标准答案之间的重叠情况，并跟踪候选答案是否与黄金标准答案的任何部分矛盾。

系统：
按照以下步骤操作。

步骤1：逐步论证提交的答案与专家答案之间的关系是：不相交、子集、超集还是具有相等的信息集。

步骤2：逐步论证提交的答案是否与专家答案的任何方面相矛盾。

步骤3：输出结构化的 JSON 对象：{"containment": "disjoint" or "subset" or "superset" or "equal", "contradiction": True or False}

以下是一个回答不够好的示例输入：

系统：
<insert system message above>

用户：
问题：“尼尔·阿姆斯特朗最出名的事件是什么，何时发生？假设使用协调世界时（UTC）。"

提交的答案：“难道他没有在月球上行走吗？"

专家答案：“尼尔·阿姆斯特朗因成为第一个踏上月球的人而闻名。这

一历史性事件发生在1969年7月21日，作为美国国家航空航天局阿波罗11号任务的一部分。阿姆斯特朗在登上月球表面时说的著名话语“这是人类的一小步，也是人类的一大步”至今仍被广泛引用。”

以下是一个好答案的示例输入：

系统：
<insert system message above>

用户：
问题：“尼尔·阿姆斯特朗最出名的事件是什么，何时发生？假设使用协调世界时（UTC）。"

提交的答案：“大约在UTC时间02:56于1969年7月21日，尼尔·阿姆斯特朗成为第一个踏上月球表面的人，标志着人类历史上的一项重大成就。巴兹·奥尔德林（Buzz Aldrin）在大约20分钟后加入了他。”
 
专家答案：“尼尔·阿姆斯特朗因成为第一个踏上月球的人而闻名。这一历史性事件发生在1969年7月21日，作为阿波罗11号任务的一部分。”

